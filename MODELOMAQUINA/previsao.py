# -*- coding: utf-8 -*-
"""Previsao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jh1oFbJsmkwURwFDvpLB8HuafPJNWxUt
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
from datetime import datetime
import seaborn as sns

df = pd.read_csv('dadosfinal2.csv')

df.head()

df = df.drop('Bairro', axis=1)

df

"""Dicionario de dados
Status - 1 Evadidos, 0 Cursando
"""

import pandas as pd
from datetime import datetime
# Converter a coluna 'Data de Nascimento' para o formato datetime
df['Data de Nascimento'] = pd.to_datetime(df['Data de Nascimento'])

# Calcular a idade com base na data atual
data_atual = datetime.now()
df['Idade'] = data_atual.year - df['Data de Nascimento'].dt.year

# Exibir o DataFrame com a coluna de idade adicionada
print(df)

df = df.drop('Data de Nascimento', axis=1)

df

# Contar a quantidade de ocorrências de cada classe na coluna "Status"
contagem_status = df['Status'].value_counts()

# Exibir a contagem de ocorrências
print(contagem_status)

# prompt: ver a quantidade de nulos em cada colunas

df.isnull().sum()

df.info()

df_encoded = df
df_encoded = pd.get_dummies(df, drop_first=True)

# Separar os dados em features (X) e target (y)
X = df_encoded.drop(columns=['Status'])  # Features
y = df_encoded['Status']  # Target variable

# Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de árvore de decisão com max_depth=4
modelo = DecisionTreeClassifier(max_depth=4)
modelo.fit(X_train, y_train)

# Fazer previsões no conjunto de teste
y_pred = modelo.predict(X_test)

# Identificar os alunos que evadiram com base nas previsões
alunos_evadidos = df.loc[y_test[y_test != y_pred].index, 'Nome']

# Exibir os nomes dos alunos que evadiram
print("Alunos que evadiram:")
print(alunos_evadidos)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier


# Salvar a coluna 'Nome' em uma variável separada
nomes_alunos = df['Nome']

# Remover a coluna 'Nome' antes de codificar as variáveis
df_encoded = df.drop(columns=['Nome'])
df_encoded = pd.get_dummies(df_encoded, drop_first=True)

# Separar os dados em features (X) e target (y)
X = df_encoded.drop(columns=['Status'])  # Features
y = df_encoded['Status']  # Target variable

# Dividir os dados em conjunto de treinamento e conjunto de teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo de árvore de decisão com max_depth=4
modelo = DecisionTreeClassifier(max_depth=4)
modelo.fit(X_train, y_train)

# Fazer previsões no conjunto de teste
y_pred = modelo.predict(X_test)

# Identificar os alunos que evadiram com base nas previsões
alunos_evadidos = nomes_alunos[y_test[y_test != y_pred].index]

# Adicionar a coluna 'Nome' novamente ao DataFrame
df_evadidos = pd.DataFrame({'Nome': alunos_evadidos})

# Exibir os nomes dos alunos que evadiram
print("Alunos que evadiram:")
print(df_evadidos)

y_pred = modelo.predict(X_test)

# Calcular a acurácia do modelo
acuracia = accuracy_score(y_test, y_pred)
print("Acurácia do modelo:", acuracia)

df_encoded = pd.get_dummies(df.drop(['Nome', 'Status'], axis=1), drop_first=True)
X = df_encoded  # Todas as colunas exceto 'Status'
y = df['Status']  # A coluna 'Status'

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

modelo = DecisionTreeClassifier(max_depth=4)
modelo.fit(X_train, y_train)

# Suponha que você queira calcular a probabilidade para todo o conjunto de dados (ou ajuste conforme necessário)
probabilidades = modelo.predict_proba(X)[:, 1]  # Probabilidade da classe positiva
df_resultado = pd.DataFrame({
    'name': df['Nome'],
    'probability': probabilidades
})

# Salvar no CSV
df_resultado.to_csv('students_dropout_probabilities.csv', index=False)

# Exibir a matriz de confusão
print("\nMatriz de Confusão:")
print(confusion_matrix(y_test, y_pred))

# Exibir o relatório de classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred))

plt.figure(figsize=(20, 15))  # Ajuste o tamanho total da figura
plot_tree(modelo, filled=True, feature_names=X.columns, class_names=['0', '1'], rounded=True, fontsize=10)  # Ajuste o tamanho da fonte
plt.show()

# Calcular a importância das características no modelo
feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': modelo.feature_importances_})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False).head(10)

# Crie um gráfico de barras mostrando apenas as top 5 características
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importances)
plt.title('Top 5 Características Mais Importantes no Modelo')
plt.xlabel('Importância')
plt.show()

